---
title: "Biomass Report"
author: "Lindsey Bell"
format: html
editor: visual
echo: false
message: false
warning: false
output-dir: docs
---
# Update 8/14/2025
## Overview
This report presents additional exploration of biomass estimates derived from canopy area measurements, with a focus on
-   Refining the parameterization of the canopy segmentation algorithm
-   Characterizing errors associated with that algorithm
## Canopy Area Allometric Model
We modeled a simple allometric relationship between canopy area and aboveground biomass by extending the previously established relationship between diameter at root crown and biomass for mesquite trees. Model parameters were derived from observations at the site's biometric gradient. The model is non-linear, causing larger tree canopies to disproportionately impact the total site biomass compared to smaller canopies. Biomass estimates throughout the remainder of this update are predicted from this model.
```{r}
#| fig-align: center
#| fig-width: 8
#| fig-height: 4

library(dplyr)
library(ggplot2)

SRGdat <-  read.csv("../Data/GitData/US-SRG_BiometGrad_07062025.csv")%>%
  #mutate(Site = "US-SRG")%>%
  group_by(ID)%>%
  summarize(BasalDi = mean(BasalDiameter, na.rm = T),
            CanopyDi = mean(CanopyDiameter, na.rm = T))%>%
  mutate(biomass = exp((-2.9255) + 2.4109 * log(BasalDi)))%>% #in kg
  #select(-BasalDi)%>%
  mutate(area = pi*((CanopyDi/2)^2),
         method = "Allometry")

model <- nls(biomass ~ a * area^b,
             data = SRGdat,
             start = list(a = 0.1, b = 1)
)


#coeffs
a_val <- unname(coef(model)["a"])
b_val <- unname(coef(model)["b"])

eq_label <- bquote(y == .(round(a_val, 3)) ~ x^.(round(b_val, 3)))
#equn label string
eq_label <- bquote(y == .(round(a_val, 3)) ~ x^.(round(b_val, 3)))

ggplot(SRGdat, aes(x = area, y = biomass)) +
  geom_point() +
  stat_function(fun = function(x) {
    a_val * x^b_val
  }, color = "lightblue", size = 1) +
  annotate("text", 
           x = max(SRGdat$area) * 0.7, 
           y = max(SRGdat$biomass) * 0.9, 
           label = as.expression(eq_label),
           parse = TRUE,
           size = 5) +
  theme_minimal() +
  labs(
    title = "",
    y = "Biomass (kg)",
    x = "Canopy Area (m2)"
  )+
  theme(axis.text.x = element_text(size = 12),
          axis.text.y = element_text(size = 12),
          axis.title.x = element_text(size = 14.5),
          axis.title.y = element_text(size = 14.5))

```
## Latin Hypercube Sampling
Latin hypercube sampling (LHS) is a stratified sampling technique that efficiently explores multiple parameter combinations by evenly representing each parameter range across the set of samples. We used LHS to evaluate 3,000 combinations of eight parameters used in the tree detection/canopy segmentation algorithms. For each parameter combination, we fit a lognormal distribution to the automatically delineated canopy areas and calculated the log-likelihood of the manually measured canopy areas. We also calculated the median canopy area difference, Kolmogorov-Smirnov (KS) statistic, and tree count difference to assess performance.
```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 12
library(tidyverse)
library(ggplot2)
library(patchwork)

results_df <- readRDS("../Data/lhs_parameterization_3000results_withdlnorm.rds")

#params
param_cols <- c("a", "b", "floor_thresh", "floor_val", 
                "th_tree", "th_seed", "th_cr", "max_cr")

#bin values
bin_param <- function(x, width) round(x / width) * width

# apply binning
results_clean <- results_df %>%
  mutate(
    a             = bin_param(a, 0.1),
    b             = bin_param(b, 0.1),
    floor_thresh  = bin_param(floor_thresh, 0.2),
    th_seed       = bin_param(th_seed, 0.2),
    th_cr         = bin_param(th_cr, 0.2),
    floor_val     = bin_param(floor_val, 0.3),
    th_tree       = bin_param(th_tree, 0.5),
    max_cr        = round(max_cr)  # integer
  )

# Define fig labels and source
output_vars <- c("overlap", "count_diff", "median_diff", "D")
yaxis_titles <- c("Overlap", "Crown Difference", "Median Difference", "KS Test")

param_labels <- c(
  a = "Slope",
  b = "Intercept",
  floor_thresh = "Min Height",
  floor_val = "Default Size",
  th_tree = "Min Treetop",
  th_seed = "Min Seed",
  th_cr = "Crown Ratio",
  max_cr = "Max Crown"
)

# Make plots
plot_list <- list()

for (i in seq_along(output_vars)) {
  output_var <- output_vars[i]
  y_title <- yaxis_titles[i]
  
  param_long <- results_clean %>%
    pivot_longer(cols = all_of(param_cols),
                 names_to = "parameter", values_to = "param_value") %>%
    select(parameter, param_value, all_of(output_var)) %>%
    rename(output_value = all_of(output_var))
  
  # Ensure numeric ordering on x-axis
  param_long$param_value <- factor(param_long$param_value, 
                                   levels = sort(unique(as.numeric(param_long$param_value))))
  
  p <- ggplot(param_long, aes(x = param_value, y = output_value)) +
    geom_boxplot(fill = "lightblue", alpha = 0.8) +
    facet_wrap(~parameter, scales = "free_x",
               labeller = as_labeller(param_labels)) +
    labs(x = "", y = y_title) +
    theme_minimal(base_size = 14) +
    theme(axis.text.x = element_text(size = 16, angle = 60, hjust = 1),
          axis.text.y = element_text(size = 14),
          strip.text = element_text(size = 16),
          axis.title.y = element_text(size = 16))
  
  plot_list[[i]] <- p
}

combined_plot <- wrap_plots(plotlist = plot_list, ncol = 2)
combined_plot
```
We filtered the parameter sets and only kept those meeting the following criteria (in a comparison of the manual and auto delineated canopies):
-   median canopy area difference \< 5 m2
-   tree count difference \< 50
-   canopy area distribution overlap \> 84%
-   KS test D value \< 0.3 (p value \< 0.05)
Then, we chose the 300 parameter sets with the highest log likelihood values to characterize the variability in modeled canopy area, tree count, and canopy cover.
```{r}
#| fig-align: center
#| fig-width: 8
#| fig-height: 4

library(dplyr)
library(tidyr)
library(ggplot2) 

results_df <- readRDS("../Data/lhs_parameterization_3000results_withdlnorm.rds")

opt_params <- results_df %>%
  filter(median_diff < 5,
         overlap > 0.84,
         count_diff < 50,
         D < 0.3,
         p_value < 0.05) %>%
  arrange(desc(log_likelihood))

topparams <- opt_params[1:300,]
lhs_results <- topparams

summary_stats <- lhs_results %>%
  summarise(
    biomass_mean = mean(total_biomass_Mg_per_ha, na.rm = TRUE),
    biomass_sd = sd(total_biomass_Mg_per_ha, na.rm = TRUE),
    biomass_median = median(total_biomass_Mg_per_ha, na.rm = TRUE),
    biomass_IQR_lower = quantile(total_biomass_Mg_per_ha, 0.25, na.rm = TRUE),
    biomass_IQR_upper = quantile(total_biomass_Mg_per_ha, 0.75, na.rm = TRUE),
    
    cover_mean = mean(canopy_cover_pct, na.rm = TRUE),
    cover_sd = sd(canopy_cover_pct, na.rm = TRUE),
    cover_median = median(canopy_cover_pct, na.rm = TRUE),
    cover_IQR_lower = quantile(canopy_cover_pct, 0.25, na.rm = TRUE),
    cover_IQR_upper = quantile(canopy_cover_pct, 0.75, na.rm = TRUE),
    
    treecount_mean = mean(total_individuals, na.rm = TRUE),
    treecount_sd = sd(total_individuals, na.rm = TRUE),
    treecount_median = median(total_individuals, na.rm = TRUE),
    treecount_IQR_lower = quantile(total_individuals, 0.25, na.rm = TRUE),
    treecount_IQR_upper = quantile(total_individuals, 0.75, na.rm = TRUE)
  )


metrics_df <- lhs_results %>% select(total_biomass_Mg_per_ha, canopy_cover_pct, total_individuals)

metrics_long <- metrics_df %>%
  pivot_longer(cols = everything(), names_to = "metric", values_to = "value")

# Descriptive labels for metrics
metric_labels <- c(
  total_biomass_Mg_per_ha = "Total Biomass (Mg/ha)",
  canopy_cover_pct = "Canopy Cover (%)",
  total_individuals = "Number of Trees"
)

# Compute median and IQR for each metric
summary_stats <- metrics_long %>%
  group_by(metric) %>%
  summarise(
    median_val = median(value, na.rm = TRUE),
    IQR_lower = quantile(value, 0.25, na.rm = TRUE),
    IQR_upper = quantile(value, 0.75, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    label = paste0("Median = ", round(median_val,2), 
                   "\nIQR = [", round(IQR_lower,2), ", ", round(IQR_upper,2), "]")
  )

ggplot(metrics_long, aes(x = value)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", alpha = 0.6) +
  geom_density(color = "darkblue", size = 1) +
  facet_wrap(~ metric, scales = "free", 
             labeller = as_labeller(metric_labels), 
             strip.position = "bottom") +
  theme_minimal() +
  theme(
    strip.background = element_blank(),
    strip.placement = "outside",
    strip.text = element_text(size = 14), 
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12.5)
  ) +
  labs(
    title = "",
    x = "",
    y = "Density"
  ) +
  geom_text(
    data = summary_stats,
    aes(
      x = Inf, y = Inf, label = label
    ),
    inherit.aes = FALSE,
    hjust = 1.1, vjust = 1.1,
    size = 4
  )


```
We compared three metrics derived from delineated canopies and from field observations. Manual delineations overpredicted biomass by 64%, overpredicted canopy cover by 21%, and underpredicted tree count by 30% relative to field observations. The automated model performed similarly, overpredicting biomass by 40%, overpredicting canopy cover by 20%, and underpredicting tree count by 35%. The automated and manually delineated estimates aligned closely, but deviated noticeably from field totals.
```{r}
#| fig-align: center
#| fig-width: 8
#| fig-height: 3
library(terra)
library(dplyr)
library(tidyr)
library(gt)

# ---------------------------
# 0. Load top parameters (for auto-detection)
# ---------------------------
results_df <- readRDS("../Data/lhs_parameterization_3000results_withdlnorm.rds")

opt_params <- results_df %>%
  filter(median_diff < 5,
         overlap > 0.84,
         count_diff < 50,
         D < 0.3,
         p_value < 0.05) %>%
  arrange(desc(log_likelihood))

topparams <- opt_params[1:300,]

# ---------------------------
# 1. Load & prepare manual canopy polygons
# ---------------------------
canpol <- vect("../Data/GitData/canopypolys.shp")
survey_outline <- vect("../QGIS/100msurveybuffer.shp")
canpol_crop <- crop(canpol, survey_outline)
canpol_crop$area <- expanse(canpol_crop, unit = "m")

canpol_df <- as.data.frame(canpol_crop)
canpol_df$predicted_biomass <- predict(model, newdata = canpol_df)
canpol_df$biomass_Mg <- canpol_df$predicted_biomass / 1000

survey_area_m2 <- as.numeric(expanse(survey_outline, unit = "m"))

man_delin <- canpol_df %>%
  summarise(
    canopy_cover_pct = (sum(area, na.rm = TRUE) / survey_area_m2) * 100,
    total_biomass_Mg = sum(biomass_Mg, na.rm = TRUE),
    total_individuals = n()
  ) %>%
  mutate(
    total_biomass_Mg_per_ha = total_biomass_Mg / (survey_area_m2 / 10000),
    method = "Manual_Detection"
  ) %>%
  select(-total_biomass_Mg)

# ---------------------------
# 2. Load & prepare field observations
# ---------------------------
veg_dat <- read.csv("../Data/GitData/US-SRG_WoodyPlantCensus_28052025.csv")
species_list <- c("ACIA", "CHAC", "GTN", "HAC", "MES", "WAC", "WTA", "Salix")

obsdf <- veg_dat %>% filter(Species %in% species_list) %>% select(ID, Species)
CD_wide <- veg_dat %>%
  select(ID, CrownDiameter) %>%
  group_by(ID) %>%
  mutate(diam_order = row_number()) %>%
  ungroup() %>%
  pivot_wider(names_from = diam_order, values_from = CrownDiameter, names_prefix = "Di_") %>%
  select(ID, Di_1, Di_2)

elp_obs <- merge(obsdf, CD_wide, by = "ID") %>%
  mutate(canopy_area = pi * (Di_1 / 2) * (Di_2 / 2),
         predicted_biomass = predict(model, newdata = data.frame(area = canopy_area)))

fieldobs_total <- elp_obs %>%
  summarise(
    total_individuals = nrow(elp_obs),
    total_biomass_Mg_per_ha = (sum(predicted_biomass, na.rm = TRUE)/1000) / (survey_area_m2/10000),
    canopy_cover_pct = (sum(canopy_area, na.rm = TRUE) / survey_area_m2) * 100,
    method = "Field_Observations"
  )

# ---------------------------
# 3. Prepare auto-detection results
# ---------------------------
metrics_long <- topparams %>%
  select(total_biomass_Mg_per_ha, canopy_cover_pct, total_individuals) %>%
  pivot_longer(cols = everything(), names_to = "metric", values_to = "value")

auto_results <- metrics_long %>%
  group_by(metric) %>%
  summarise(
    median = median(value, na.rm = TRUE),
    IQR_lower = quantile(value, 0.25, na.rm = TRUE),
    IQR_upper = quantile(value, 0.75, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(IQR = paste0(round(IQR_lower, 2), "–", round(IQR_upper, 2)),
         method = "Auto_Detection") %>%
  select(method, metric, median, IQR)

# ---------------------------
# 4. Combine all methods, stacked by metric
# ---------------------------
man_field_summary <- rbind(man_delin, fieldobs_total) %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "median") %>%
  mutate(IQR = NA_character_)

summary_all_long <- bind_rows(man_field_summary, auto_results) %>%
  mutate(
    method = factor(method, levels = c("Field_Observations", "Manual_Detection", "Auto_Detection")),
    Metric = case_when(
      metric == "total_biomass_Mg_per_ha" ~ "Total Biomass (Mg/ha)",
      metric == "canopy_cover_pct" ~ "Canopy Cover (%)",
      metric == "total_individuals" ~ "Number of Trees"
    )
  ) %>%
  select(Metric, Method = method, Median = median, IQR)

# ---------------------------
# 5. Create GT table
# ---------------------------
gt_table <- summary_all_long %>%
  gt() %>%
  tab_header(title = "Comparison of Canopy Metrics Across Methods") %>%
  fmt_number(columns = c(Median), decimals = 2) %>%
  cols_label(Median = "Median", IQR = "IQR (25–75%)") %>%
  tab_style(style = cell_text(weight = "bold"), locations = cells_column_labels(everything()))

gt_table


```
We also selected the parameter set with the highest log-likelihood value from the top 300 parameter sets to characterize canopies at the site and to compare results to the manual delineations and field observations. This set of parameters slightly underestimates larger canopies (blue), but detects more clumps of smaller canopies. 
```{r}
#| fig-align: center
#| fig-width: 6
#| fig-height: 4
# Load data
library(terra)

# Load data
manu <- vect("../Data/GitData/canopypolys.shp")
auto_new <- vect("../Data/topparams_08142025report.shp")

# Compute differences
overpred <- erase(auto_new, manu)   # auto_new minus manual
underpred <- erase(manu, auto_new)  # manual minus auto_new

# Plot differences only
plot(overpred, col="red", border=NA, main="Canopy Prediction Differences", axes=FALSE)
plot(underpred, col="blue", border=NA, add=TRUE)

```
We compare distributions of canopy area and height for the field observations, manually delineated canopies, and automatically delineated canopies (using the top parameter set). Field observations contained a higher proportion of small canopy areas compared to the delineated canopy datasets. Additionally, the height distribution from the observed data was more uniform, exhibiting a more gradual incline compared to the steeper distribution observed in the delineated canopies.
```{r}
#| fig-align: center
#| fig-width: 8
#| fig-height: 5

library(terra)
library(sf)
library(dplyr)
library(tidyr)
library(ggplot2)
library(viridis)
library(lidR)   # for locate_trees

#-----------------------------
# Load CHM
#-----------------------------
chm <- rast("../Data/GitData/SRGchm.RDS")  # your CHM raster

#-----------------------------
# Detect treetops and extract height
#-----------------------------
ttops <- locate_trees(
  chm,
  algorithm = lmf(ws = 3, hmin = 1)
)

ttops_sf <- st_as_sf(ttops)
ttops_sf$height <- terra::extract(chm, vect(ttops_sf))[,2]

#-----------------------------
# Load auto-delineated polygons
#-----------------------------
auto_polygons <- st_read("../Data/topparams_08142025report.shp", quiet = TRUE)
auto_polygons$area <- as.numeric(st_area(auto_polygons))

# Assign nearest treetop height to each polygon
auto_centroids <- st_centroid(auto_polygons)
nearest_ttops <- st_nearest_feature(auto_centroids, ttops_sf)
auto_polygons$height <- ttops_sf$height[nearest_ttops]

auto_df <- data.frame(
  CanopyArea = auto_polygons$area,
  Height     = auto_polygons$height,
  Method     = "Auto"
)

#-----------------------------
# Manual polygons
#-----------------------------
canpol <- vect("../Data/GitData/canopypolys.shp")

chm_crop <- crop(chm, canpol)
chm_masked <- mask(chm_crop, canpol)

max_height <- terra::extract(chm_masked, canpol, fun = max, na.rm = TRUE)
height_values <- max_height[,2]  # second column usually contains CHM values

areas <- expanse(canpol, unit = "m")

manual_df <- data.frame(
  CanopyArea = areas,
  Height     = height_values,
  Method     = "Manual"
)

#-----------------------------
# Field observations
#-----------------------------
veg_dat <- read.csv("../Data/GitData/US-SRG_WoodyPlantCensus_28052025.csv")
species_list <- c("ACIA", "CHAC", "GTN", "HAC", "MES", "WAC", "WTA", "Salix")

obsdf <- veg_dat %>%
  filter(Species %in% species_list) %>%
  dplyr::select(ID, Height)

CD_wide <- veg_dat %>%
  dplyr::select(ID, CrownDiameter) %>%
  group_by(ID) %>%
  mutate(diam_order = row_number()) %>%
  ungroup() %>%
  pivot_wider(names_from = diam_order, values_from = CrownDiameter, names_prefix = "Di_") %>%
  dplyr::select(ID, Di_1, Di_2)

field_df <- merge(obsdf, CD_wide, by = "ID") %>%
  reframe(
    CanopyArea = pi * (Di_1 / 2) * (Di_2 / 2),
    Height     = Height,
    Method     = "Field"
  )

#-----------------------------
# Combine all datasets
#-----------------------------
topparam_combo_df <- bind_rows(auto_df, manual_df, field_df)

metrics_long <- topparam_combo_df %>%
  pivot_longer(cols = c(Height, CanopyArea),
               names_to = "Metric",
               values_to = "Value")

#-----------------------------
# Plot histogram + density
#-----------------------------
ggplot(metrics_long, aes(x = Value, fill = Method)) +
  geom_histogram(aes(y = ..density..), bins = 30, alpha = 0.5, position = "identity") +
  geom_density(alpha = 0.6) +
  facet_wrap(
    ~ Metric,
    scales = "free",
    switch = "x",
    labeller = labeller(
      Metric = c(
        CanopyArea = "Canopy Area (m²)",
        Height     = "Height (m)"
      )
    )
  ) +
  scale_fill_viridis_d(option = "plasma") +
  labs(x = NULL, y = "Density") +
  theme_minimal(base_size = 14) +
  theme(
    axis.title.y = element_text(vjust = 1.5),
    strip.text.x = element_text(size = 14),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12),
    strip.placement = "outside"
  )
```
## Canopy Errors
Due to the substantial differences in trees detected, biomass, and canopy area between the observed and delineated canopies, we investigated sources of error. We attribute the under-performance of the canopy delineations to two types of error:
-   Detection error: inaccuracies in identifying the presence or absence of a tree.
-   Segmentation error: inaccuracies in defining individual canopy boundaries, such as merging multiple canopies into one or fragmenting a single canopy into several parts.
Detection errors primarily affect small trees, since large trees  naturally occupy more area and have denser canopies, making them more likely to be detected. Because small trees are abundant at the site, a model's ability to detect canopies below a certain size threshold can cause substantial variability in the total number of individuals recorded. However, while small-canopied trees contribute largely to tree counts, their contribution to total biomass is minimal until a considerable number of these canopies are left undetected. 
```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 5

library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)

#-----------------------------
# Field observations
#-----------------------------
veg_dat <- read.csv("../Data/GitData/US-SRG_WoodyPlantCensus_28052025.csv")
species_list <- c("ACIA", "CHAC", "GTN", "HAC", "MES", "WAC", "WTA", "Salix")

obsdf <- veg_dat %>%
  dplyr::select(ID, Species, Height) %>%
  filter(Species %in% species_list)

CD_df <- veg_dat %>%
  dplyr::select(ID, CrownDiameter)

CD_wide <- CD_df %>%
  group_by(ID) %>%
  mutate(diam_order = row_number()) %>%
  ungroup() %>%
  pivot_wider(names_from = diam_order, values_from = CrownDiameter, names_prefix = "Di_") %>%
  dplyr::select(ID, Di_1, Di_2)

field_paramcomp <- merge(obsdf, CD_wide, by = "ID") %>%
  reframe(
    CanopyArea = pi * (Di_1 / 2) * (Di_2 / 2),
    Height = Height,
    Method = "Field_Observations"
  ) %>%
  mutate(predicted_biomass_Mg = (predict(model, newdata = data.frame(area = CanopyArea)))/1000) %>%
  arrange(CanopyArea)  # smallest first

#-----------------------------
# Initialize sensitivity data frame
#-----------------------------
n_individuals <- nrow(field_paramcomp)
biomass_sensitivity <- data.frame(
  trees_excluded = 0:(n_individuals - 1),
  trees_remaining = n_individuals:1,
  total_biomass = NA,
  min_area_excluded = NA
)

#-----------------------------
# Loop to calculate biomass
#-----------------------------
for (i in 1:n_individuals) {
  subset_df <- field_paramcomp %>% slice(i:n_individuals)
  biomass_sensitivity$total_biomass[i] <- sum(subset_df$predicted_biomass_Mg, na.rm = TRUE)
  biomass_sensitivity$min_area_excluded[i] <- min(subset_df$CanopyArea, na.rm = TRUE)
}

#-----------------------------
# Rescale min_area_excluded for secondary axis
#-----------------------------
areas <- biomass_sensitivity$min_area_excluded
areas <- areas[is.finite(areas)]
range_biomass <- range(biomass_sensitivity$total_biomass, na.rm = TRUE)
range_area    <- range(areas)

biomass_sensitivity$min_area_scaled <- scales::rescale(
  biomass_sensitivity$min_area_excluded,
  to = range_biomass
)

#-----------------------------
# Plot
#-----------------------------
p1 <- ggplot(biomass_sensitivity, aes(x = trees_excluded)) +
  geom_line(aes(y = total_biomass), color = "steelblue", size = 1) +
  geom_line(aes(y = min_area_scaled), color = "darkgreen", size = 1, linetype = "dashed") +
  theme_minimal(base_size = 14) +
  labs(
    x = "# of Excluded Canopies",
    y = "Total Biomass (Mg)",
    title = ""
  ) +
  scale_y_continuous(
    sec.axis = sec_axis(
      trans = ~ scales::rescale(., to = range_area),
      name = "Minimum Canopy Area Remaining (m2)",
      breaks = seq(floor(min(areas)/20)*20, ceiling(max(areas)/20)*20, by = 20)
    )
  )

library(dplyr)
library(ggplot2) 

results_df <- readRDS("../Data/lhs_parameterization_3000results_withdlnorm.rds")

opt_params <- results_df %>%
  filter(median_diff < 5,
         overlap > 0.84,
         count_diff < 50,
         D < 0.3,
         p_value < 0.05) %>%
  arrange(desc(log_likelihood))

topparams <- opt_params[1:300,]

p2 <- ggplot(topparams, aes(x = total_individuals, y = total_biomass_Mg)) +
  geom_point(size = 3, alpha = 0.8) +
  theme_minimal(base_size = 14) +
  labs(
    x = "Total Individuals",
    y = "Total Biomass (Mg)",
    title = ""
  ) +
  theme(
    axis.title = element_text(size = 15),
    axis.text  = element_text(size = 13),
    plot.title = element_text(size = 18))
#+
  # geom_smooth(method = "lm", se = TRUE, color = "darkred", linetype = "dashed")

p1+p2
```
Given the large discrepancy in tree counts between the delineations and field observations, we investigated the role of errors associated with segmentation. We randomly split manually delineated canopies one to four times to match the total number of observed canopies and examined the resulting distribution. Larger trees had a higher probability of being composed of multiple merged canopies. Because the allometric relationship between canopy area and biomass is nonlinear, the accidental merging of multiple canopies produces artificially large canopies that can disproportionately inflate total biomass estimates for the site. Conversely, randomly segmenting canopies to create a distribution more similar to field observations increases tree counts while reducing total biomass.
```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 5
library(ggplot2)
library(viridis)

sim_df <- readRDS("../Data/simulatedsplits.RDS")
manual_df <- readRDS("../Data/LumpingProd_df.RDS")
#-----------------------------
# Plot 1: Density of Canopy Areas
#-----------------------------
p1 <- ggplot(sim_df, aes(x = CanopyArea, fill = Method)) +
  geom_density(alpha = 0.5) +
  scale_fill_manual(
    values = c(
      "Manual_Delineation" = viridis::viridis(3)[2],
      "Simulated_Splits" = viridis::viridis(3)[3],
      "Field_Observations" = viridis::viridis(3)[1]
    ),
    labels = c(
      "Manual_Delineation" = "Manual",
      "Simulated_Splits" = "Simulated",
      "Field_Observations" = "Field"
    )
  ) +
  theme_minimal(base_size = 16) +
  theme(
    legend.title = element_blank(),
    legend.text = element_text(size = 14),
    axis.title = element_text(size = 16),
    axis.text = element_text(size = 14),
    plot.title = element_text(size = 18, face = "bold")
  ) +
  labs(
    title = "",
    x = "Canopy Area (m2)",
    y = "Density"
  )

#-----------------------------
# Plot 2: Probability of lumping
#-----------------------------
p2 <- ggplot(manual_df, aes(x = CanopyArea, y = ProbLumped)) +
  geom_point(color = "darkred") +
  geom_smooth(method = "loess", se = TRUE, color = "black") +
  theme_minimal(base_size = 16) +
  theme(
    axis.title = element_text(size = 16),
    axis.text = element_text(size = 14),
    plot.title = element_text(size = 18, face = "bold")
  ) +
  labs(
    title = "",
    x = "Canopy Area (m2)",
    y = "Probability of Lumping"
  )


#-----------------------------
# Combine plots
#-----------------------------
p2 + p1
```
Although tree presence can be reliably determined in the field, canopy area measurements are more uncertain due to irregular canopy shapes. Standard field practice involves measuring the major and minor axes of the canopy, but these axes can be difficult to accurately and quickly identify from the ground. As a result, measurement error is introduced depending on the angles at which canopy diameters are assessed. Variability in canopy area estimates is associated with both the size and shape of the canopy. 

We used the modeled tree canopy polygons and generated major and minor axis diameter measurements for 18 directions within each polygon. As size increases, so does the error of the directional estimate
```{r}
#| fig-align: center
#| fig-width: 8
#| fig-height: 5

library(terra)
library(sf)
library(dplyr)
library(purrr)
library(tidyr)
library(ggplot2)
library(patchwork)

tcans <- vect("../Data/topparams_08142025report.shp")
tcans_sf <- st_as_sf(tcans) # easier for some ops
tcans_sf$id <- 1:nrow(tcans_sf)

get_diameter <- function(polygon, angle_deg) {
  cent <- st_centroid(polygon)
  cx <- st_coordinates(cent)[1]
  cy <- st_coordinates(cent)[2]
  
  angle_rad <- angle_deg * pi / 180
  dx <- cos(angle_rad)
  dy <- sin(angle_rad)
  L <- 1000
  line_coords <- matrix(c(cx - L*dx, cy - L*dy,
                          cx + L*dx, cy + L*dy),
                        ncol=2, byrow=TRUE)
  line <- st_sfc(st_linestring(line_coords), crs = st_crs(polygon))
  
  # Intersection
  inter <- st_intersection(polygon, line)
  if (nrow(st_coordinates(inter)) < 2) return(NA)
  
  coords <- st_coordinates(inter)[,1:2]
  dist_matrix <- as.matrix(dist(coords))
  max_dist <- max(dist_matrix)
  return(max_dist)
}

estimate_canopy_areas <- function(polygon, angles) {
  diameters <- map_dbl(angles, ~ get_diameter(polygon, .x))
  perp_diameters <- map_dbl(angles, ~ get_diameter(polygon, .x + 90))
  
  est_areas <- pi * (diameters/2) * (perp_diameters/2)
  true_area <- as.numeric(st_area(polygon))
  return(c(true_area, est_areas))
}

angles <- seq(0, 85, by = 5)

results <- tcans_sf %>%
  rowwise() %>%
  mutate(vals = list(estimate_canopy_areas(geometry, angles))) %>%
  ungroup()

out_df <- results %>%
  mutate(vals = map(vals, ~ setNames(.x, c("True_area", paste0("est", 1:18))))) %>%
  unnest_wider(vals)

#plotting-----------------------------------------------------------------------
# Pivot out_df to long format
df_long <- out_df %>%
  pivot_longer(cols = starts_with("est"), 
               names_to = "angle_est", 
               values_to = "area_est") %>%
  mutate(id = id)

p1 <- ggplot(df_long, aes(x = True_area, y = area_est)) +
  geom_point(alpha = 0.4, color = "black") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  theme_minimal(base_size = 16) +  # increase base font size
  labs(
    x = "True Canopy Area (m2)",
    y = "Direction-Based Estimated Area (m2)",
    title = ""
  ) +
  theme(
    axis.title = element_text(size = 15),   # axis titles larger
    axis.text = element_text(size = 13),    # axis tick labels larger
    plot.title = element_text(size = 20)    # if you add a title
  )
df_summary <- df_long %>%
  group_by(id, True_area) %>%
  summarise(mean_est = mean(area_est, na.rm = TRUE),
            sd_est = sd(area_est, na.rm = TRUE),
            .groups = "drop")

# Fit a model of SD as a function of canopy area (log-log is common for variance modeling)
sd_model <- lm(sd_est ~ True_area, data = df_summary)

# Create prediction data
pred_df <- data.frame(True_area = seq(min(df_summary$True_area),
                                      max(df_summary$True_area),
                                      length.out = 100))
pred_df$sd_pred <- predict(sd_model, newdata = pred_df)

# Plot
p2 <- ggplot(df_summary, aes(x = True_area, y = sd_est)) +
  geom_point(size = 2, color = "black") +
  geom_line(data = pred_df, aes(y = sd_pred), color = "lightblue", size = 1) +
  theme_minimal(base_size = 16) +  # increase base font size
  labs(
    x = "True Canopy Area (m2)",
    y = "Standard Deviation of Estimates",
    title = ""
  ) +
  theme(
    axis.title = element_text(size = 15),   # axis titles larger
    axis.text  = element_text(size = 13)    # if you add a title
  )

p1+p2
```
Likewise, we used these canopy polygons to assess the error associated with canopies of irregular shapes (i.e., deviation from a smooth ellipse). As the canopy shape deviates from an ellipse, irregularity increases, and error increases. 
```{r}
#| fig-align: center
#| fig-width: 8
#| fig-height: 5
#=============================
# Self-contained Canopy Analysis
#=============================

library(terra)
library(sf)
library(dplyr)
library(purrr)
library(tidyr)
library(ggplot2)
library(patchwork)

#-----------------------------
# Load canopy polygons
#-----------------------------
tcans <- vect("../Data/topparams_08142025report.shp")
tcans_sf <- st_as_sf(tcans)
tcans_sf$id <- 1:nrow(tcans_sf)

#-----------------------------
# Functions to estimate areas
#-----------------------------
get_diameter <- function(polygon, angle_deg) {
  cent <- st_centroid(polygon)
  cx <- st_coordinates(cent)[1]
  cy <- st_coordinates(cent)[2]
  
  angle_rad <- angle_deg * pi / 180
  dx <- cos(angle_rad)
  dy <- sin(angle_rad)
  L <- 1000
  line_coords <- matrix(c(cx - L*dx, cy - L*dy,
                          cx + L*dx, cy + L*dy),
                        ncol=2, byrow=TRUE)
  line <- st_sfc(st_linestring(line_coords), crs = st_crs(polygon))
  
  inter <- st_intersection(polygon, line)
  if (nrow(st_coordinates(inter)) < 2) return(NA)
  
  coords <- st_coordinates(inter)[,1:2]
  dist_matrix <- as.matrix(dist(coords))
  max(dist_matrix)
}

estimate_canopy_areas <- function(polygon, angles) {
  diameters <- map_dbl(angles, ~ get_diameter(polygon, .x))
  perp_diameters <- map_dbl(angles, ~ get_diameter(polygon, .x + 90))
  est_areas <- pi * (diameters/2) * (perp_diameters/2)
  true_area <- as.numeric(st_area(polygon))
  c(True_area = true_area, est_areas)
}

angles <- seq(0, 85, by = 5)

#-----------------------------
# Compute estimated areas
#-----------------------------
results <- tcans_sf %>%
  rowwise() %>%
  mutate(vals = list(estimate_canopy_areas(geometry, angles))) %>%
  ungroup() %>%
  mutate(vals = map(vals, ~ setNames(.x, c("True_area", paste0("est", 1:(length(.x)-1)))))) %>%
  unnest_wider(vals)
#-----------------------------
# Pivot to long format for SD calculation
#-----------------------------
df_long <- results %>%
  pivot_longer(cols = starts_with("est"),
               names_to = "angle_est",
               values_to = "area_est") %>%
  filter(!is.na(area_est))

df_summary <- df_long %>%
  group_by(id, True_area) %>%
  summarise(mean_est = mean(area_est, na.rm = TRUE),
            sd_est   = sd(area_est, na.rm = TRUE),
            .groups = "drop")

#-----------------------------
# Compute canopy irregularity
#-----------------------------
area_m2 <- expanse(tcans)
perim_m <- perim(tcans)

get_width_height <- function(polygon) {
  e <- ext(polygon)
  width <- e$xmax - e$xmin
  height <- e$ymax - e$ymin
  c(width = width, height = height)
}

wh <- t(sapply(1:length(tcans), function(i) get_width_height(tcans[i])))
colnames(wh) <- c("width", "height")

a <- wh[, "width"]/2
b <- wh[, "height"]/2

ellipse_perimeter <- function(a, b) {
  pi * (3*(a+b) - sqrt((3*a + b)*(a + 3*b)))
}

ellipse_area <- pi * a * b
scale_factor <- sqrt(area_m2 / ellipse_area)
a_scaled <- a * scale_factor
b_scaled <- b * scale_factor
ellipse_perim <- ellipse_perimeter(a_scaled, b_scaled)

irregularity_index <- perim_m / ellipse_perim

irreg_results <- data.frame(
  id = 1:length(tcans),
  area_m2 = area_m2,
  perim_m = perim_m,
  ellipse_perim = ellipse_perim,
  irregularity_index = irregularity_index
)

#-----------------------------
# Merge SD with irregularity
#-----------------------------
df_plot <- df_summary %>%
  left_join(irreg_results, by = "id")

#-----------------------------
# Plot 1: Irregularity vs SD
#-----------------------------
p1 <- ggplot(df_plot, aes(x = irregularity_index, y = sd_est)) +
  geom_point(size = 2, color = "black") +
  theme_minimal(base_size = 16) +
  labs(x = "Canopy Irregularity Index",
       y = "Standard Deviation of Estimates") +
  theme(axis.title = element_text(size = 15),
        axis.text  = element_text(size = 13))

#-----------------------------
# Plot 2: True area vs Irregularity
#-----------------------------
p2 <- ggplot(df_plot, aes(x = area_m2, y = irregularity_index)) +
  geom_point(size = 2, color = "black") +
  theme_minimal(base_size = 16) +
  labs(x = "True Canopy Area (m²)",
       y = "Canopy Irregularity Index") +
  theme(axis.title = element_text(size = 15),
        axis.text  = element_text(size = 13))

#-----------------------------
# Combine plots
#-----------------------------
p1 + p2
```

# Update 8/1/2025

## Overview

Recent field surveys and drone flights at the US-SRG flux site enabled an exploration of woody biomass estimation methods at fine and coarse spatial scales. In this report, we estimated woody biomass using three approaches:

-   Allometric equations based on field-measured basal diameter
-   Allometric equations applied to canopy metrics
-   Voxel-based calculations using high-density LiDAR

In addition to estimating total biomass at the site, we apply these methods to estimate biomass along the biometric mesquite gradient at US-SRG. Finally, we examined trends in biomass products available at the site.

## Allometry with Basal Diameter

At the end of May 2025, we conducted a woody plant census within a 100-meter radius of the US-SRG flux tower. During this survey, we recorded basal and canopy diameter for all individual shrubs and trees. To estimate aboveground biomass, we applied an allometric equation originally described by Jenkins et al. (2003) and later revised by Chojnacky et al. (2013). Given that the vegetation at US-SRG is dominated by mesquite (Prosopis spp.), we used the equation specific to Woodland Fabaceae/Rosaceae:

Biomass = exp(−2.9255 + 2.4109 × log(x))

where x is diameter at root collar (DRC) in centimeters.

We made two key assumptions in applying this relationship. First, because DRC was not measured directly, we approximated it using basal diameter measurements. Second, although the equation is primarily based on mesquite data, we include additional woody desert shrubs: hackberry (Celtis pallida), greythorn (Ziziphus obtusifolia), whitethorn acacia (Vachellia constricta), and catclaw acacia (Senegalia greggii). For multi-stemmed individuals, we used the average basal diameter across stems.

For desert willow (Chilopsis linearis), we applied a separate equation using diameter at breast height (DBH), with parameters as follows:

Biomass = exp(−2.4441 + 2.4561 × log(x))

where x is DBH in centimeters.

```{r}
#| fig-align: center
#| fig-width: 8
#| fig-height: 4
library(dplyr)
library(ggplot2)
library(patchwork)

veg_dat <- read.csv("../Data/GitData/US-SRG_WoodyPlantCensus_28052025.csv")%>%
  filter(Distance < 60)%>%
  group_by(ID)%>%
  reframe(Quadrant, 
          Species, 
          BasalDi = mean(BasalDiameter, na.rm = T))%>%
  group_by(ID)%>%
  slice(1)

bigshrubs <- veg_dat%>%
  filter(Species %in% c("ACIA", "CHAC", "GTN", "HAC", "MES", "WAC", "WTA"))
AGB_shrubs <- bigshrubs%>%
  mutate(biomass = exp((-2.9255) + 2.4109 * log(BasalDi)))

willows <- veg_dat%>%
  filter(Species == "SALIX")
AGB_willow <- willows %>% 
  filter(!is.na(BasalDi)) %>% 
  mutate(biomass = exp((-2.4441) + 2.4561 * log(BasalDi)))

AGB <- bind_rows(AGB_shrubs, AGB_willow)%>%
  mutate(Mg_biomass = biomass*0.001)
AGB_total <- sum(AGB$biomass, na.rm = T)* 0.001 #in kg, so scale by 0.001 for Mg

p1 <- ggplot(AGB, aes(x = Mg_biomass)) +
  geom_histogram(binwidth = 0.05, fill = "#1b9e77", color = "black", boundary = 0) +
  labs(title = "",
       x = "Biomass (Mg)",
       y = "Count") +
  theme_minimal()


p2 <- ggplot(AGB, aes(x = BasalDi)) +
  geom_histogram(binwidth = 5, fill = "#1b9e77", color = "black", boundary = 0) +
  labs(title = "",
       x = "Basal Diameter (cm)",
       y = "Count") +
  theme_minimal()

p2+p1
```

The total woody biomass from the census basal diameter observations is 12.66 Mg.

## Allometry with Canopy Metrics

In order to estimate biomass from canopy metrics, we modeled an empirical relationship between canopy area and woody biomass using observations from the biometric gradient:

Biomass = 0.1136 \* (Canopy Area)\^1.8890

Canopy area was derived automatically from a LiDAR-based canopy height model (CHM) using treetop detection and watershed segmentation to delineate individual tree crowns. We then applied the canopy area--biomass relationship to estimate total woody biomass within a 100-meter radius of the US-SRG flux tower for the automatically detected crowns, from manually detected crowns (see DronetoCensusComparison report in FluxandtheField repository), and crown metrics from field observations.

To detect treetops on the CHM, we used a variable window filter, where the window size is a linear function of canopy height (y = ax + b). In the function, we also include a height threshold below which a default window size is applied. To identify optimal parameters for this function, we evaluated over 1,500 combinations of values based on their ability to identify treetops and create a reasonable distribution of canopy areas relative to the manually delineated canopy crowns. More specifically, we evaluated the parameters based on the outputs':

-   Deviation in the number of detected crowns compared to manual delineation

-   Deviation in the median canopy area

-   Deviation in the distribution of canopy areas

-   Statistical difference in distribution shape (Kolmogorov--Smirnov test)

```{r}
#| fig-align: center
#| fig-width: 15
#| fig-height: 12
library(tidyverse)
library(ggplot2)
library(patchwork)

df <- readRDS("../Data/parameterization.RDS")

output_vars <- c("overlap", "count_diff", "median_diff", "D")
yaxis_titles <- c("Overlap", "Crown Difference", "Median Difference", "KS Test")

param_labels <- c(
  a = "Slope",
  b = "Intercept",
  floor_thresh = "Height Threshold",
  floor_val = "Default Size"
)

plot_list <- list()

for (i in seq_along(output_vars)) {
  output_var <- output_vars[i]
  y_title <- yaxis_titles[i]
  
  param_long <- df %>%
    pivot_longer(cols = c(a, b, floor_thresh, floor_val),
                 names_to = "parameter", values_to = "param_value") %>%
    select(parameter, param_value, all_of(output_var))
  
  colnames(param_long)[3] <- "output_value"
  
  p <- ggplot(param_long, aes(x = as.factor(param_value), y = output_value)) +
    geom_boxplot(fill = "lightblue", alpha = 0.8) +
    facet_wrap(~parameter, scales = "free_x",
               labeller = as_labeller(param_labels)) +
    labs(x = "", y = y_title) +
    theme_minimal(base_size = 14) +
    theme(axis.text.x = element_text(size = 18, angle = 60, hjust = 1),
          axis.text.y = element_text(size = 18),
          strip.text = element_text(size = 24),
          axis.title.y = element_text(size = 24))
  
  plot_list[[i]] <- p
}

combined_plot <- wrap_plots(plotlist = plot_list, ncol = 2)
combined_plot

```

The optimal window function based on the parameters tested was:

Window size = 0.6x + 0.3 Window height threshold: \< 2.6 m, window size = 4 m

This combination of parameters agreed strongly with the manually delineated canopy area metrics, resulting in a crown count difference of 1, median canopy area difference of 1.45 m2, an overlap score of 0.82, and a Kolmogorov--Smirnov D value of 0.22.

Although this method occasionally overdetects crowns in taller vegetation (left), and the segmented canopy polygons often underestimate crown area even when treetops are correctly located (right), the overall performance is comparable to the manually delineated reference.

```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 5
#| fig-cap: "Left: 0.5-m canopy height model (CHM) within 100m of the US-SRG flux tower. White circles represent automatically detected treetops. Yellow colors on the CHM indicate large values while purple colors indicate small values. Right: Difference in canopy areas between the automatically and manually detected canopies for canopies within the field survey boundary (~100m around the US-SRG tower). Blue represents an underprediction and red represents on overprediction of canopy area by the automatic detection. "

library(lidR)
library(sf)
library(terra)

custom_ws <- function(x) {
  y <- ceiling(0.6 * x + (0.3))
  y[x < 2.6] <- 4
  return(y)
}

chm_load <- rast("../Data/0.5mSRGchm.tif")
survey_outline <- vect("../QGIS/100msurveybuffer.shp")
chm_crop <- crop(chm_load, survey_outline)
chm <- chm_crop
kernel <- matrix(1,3,3)
chm_smoothed <- terra::focal(chm, w = kernel, fun = median, na.rm = TRUE)
ttops <- locate_trees(las = chm_smoothed, algorithm = lmf(ws = custom_ws, hmin=1)) # lms 2.5

#-----------------------------------------

manu_output <- vect("../Data/GitData/canopypolys.shp")
auto_output <- vect("../Data/testJiamingcrowns2.shp")
survey_outline <- vect("../QGIS/100msurveybuffer.shp")

manushp <- crop(manu_output, survey_outline)
autoshp <- crop(auto_output, survey_outline)


overpred <- erase(autoshp, manushp)
underpred <- erase(manushp, autoshp)
#-----------------------------------------
par(mfrow = c(1, 2), mar = c(1, 1, 1, 1), oma = c(0, 0, 0, 0))  # Small margins

# Plot 1: CHM + treetops
plot(
  chm_smoothed,
  axes = FALSE,
  box = FALSE,
  legend = FALSE
)
plot(ttops, col = "white", add = TRUE, cex = 0.6, pch = 14)

# Plot 2: Over- and under-prediction
plot(survey_outline,
     col = "grey90",
     border = NA,
     axes = FALSE,
     frame = FALSE,
     main = "")

plot(underpred, col = adjustcolor("blue", 0.6), add = TRUE)
plot(overpred, col = adjustcolor("red", 0.6), add = TRUE)
```

To further assess precision, we compared total woody biomass estimates derived from three sources of canopy area measurements:

Automated LiDAR-based segmentation: 11.7 Mg

Manual canopy delineation: 18.0 Mg

Field observations: 3.8 Mg

```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 8
#observations: 
library(dplyr)
library(terra)
library(ggplot2)

veg_dat <- read.csv("../Data/GitData/US-SRG_WoodyPlantCensus_28052025.csv")%>%
  filter(Distance < 60)%>%
  group_by(ID)%>%
  reframe(Quadrant, 
          Species, 
          CanDi = mean(CrownDiameter, na.rm = T))%>%
  group_by(ID)%>%
  slice(1)

obsdf <- veg_dat%>%
  filter(Species %in% c("ACIA", "CHAC", "GTN", "HAC", "MES", "WAC", "WTA", "Salix"))%>%
  mutate(area = pi*((CanDi/2)^2))

#===========================
#model from biomet grad

SRGdat <-  read.csv("../Data/GitData/US-SRG_BiometGrad_07062025.csv")%>%
  mutate(Site = "US-SRG")%>%
  group_by(ID)%>%
  summarize(BasalDi = mean(BasalDiameter, na.rm = T),
            CanopyDi = mean(CanopyDiameter, na.rm = T))%>%
  mutate(biomass = exp((-2.9255) + 2.4109 * log(BasalDi)))%>% #in kg
  #select(-BasalDi)%>%
  mutate(area = pi*((CanopyDi/2)^2),
         method = "Allometry")

model <- nls(biomass ~ a * area^b,
             data = SRGdat,
             start = list(a = 0.1, b = 1)
)

#===============================================================================
#predict polygon biomass from model above

manu_output <- vect("../Data/GitData/canopypolys.shp")
auto_output <- vect("../Data/testJiamingcrowns2.shp")
survey_outline <- vect("../QGIS/100msurveybuffer.shp")

manushp <- crop(manu_output, survey_outline)
autoshp <- crop(auto_output, survey_outline)

manushp$area <- expanse(manushp, unit = "m")
autoshp$area <- expanse(autoshp, unit = "m")
manudf <- as.data.frame(manushp)
autodf <- as.data.frame(autoshp)
manudf$predicted_biomass <- predict(model, newdata = manudf)
autodf$predicted_biomass <- predict(model, newdata = autodf)
obsdf$predicted_biomass <- predict(model, newdata = obsdf)


manudf$method <- "Manual"
autodf$method <- "Automatic"
obsdf <- obsdf%>%
  mutate(method = "Observed")%>%
  rename(id = ID,
         canopy_area = area)

# Combine both into one data frame
biomass_df <- bind_rows(manudf, autodf, obsdf)

#plotting-------------------------------
ggplot(biomass_df, aes(x = predicted_biomass, fill = method, color = method)) +
  geom_histogram(aes(y = ..density..), alpha = 0.2, position = "identity", bins = 30) +
  geom_density(alpha = 0.4, size = 1) +  # transparency here
  scale_x_log10() +  # Optional: apply if skewed
  scale_fill_viridis_d(option = "C") +
  scale_color_viridis_d(option = "C") +
  labs(x = "Predicted Biomass (kg, log scale)", y = "Density",
       title = "",
       fill = "Method", color = "Method") +
  theme_minimal()+
  theme(axis.text.x = element_text(size = 14),
          axis.text.y = element_text(size = 14),
          axis.title.x = element_text(size = 22),
          axis.title.y = element_text(size = 22),
        legend.text = element_text(size = 18),
        legend.title = element_text(size = 18))


```

## Voxelization

For the final biomass estimation method, we used voxelized a LiDAR point cloud data a cube size of 2.5 cm. Points were filtered to exclude noise and low-returns associated with grasses. Unlike the segmentation-based method, voxelization allowed us to estimate biomass across the entire area without requiring delineation of individual tree crowns.

We applied a specific wood density of 0.78 g cm-3 (Chojnacky et al., 2013), to convert voxelized volume into woody biomass. Using this method, the total estimated biomass within the survey boundary was 46.9 Mg.

It is important to note, however, that this method is highly sensitive to voxel resolution. For example, increasing the voxel side length to 5 cm resulted in a biomass estimate of 325.6 Mg. Further work is needed to understand the influence of voxel resolution on estimating biomass and what criteria is needed to select a voxel size.

## Biometric Gradient Comparison

After evaluating biomass estimation methods at the ecosystem scale, we narrowed our focus to a set of 10 individual trees spanning a wide range of heights, basal diameters, canopy diameters, and growth forms. We refer to these tree as the biometric gradient. For each tree, we estimated aboveground biomass using all available methods described above.

Voxel-based estimates consistently produced higher biomass values compared to other approaches. In contrast, the automated crown detection method tended to output lower biomass estimates. The estimates from basal diameter and canopy diameter were generally similar. This was expected since both rely on the same allometric relationship.

```{r}
#| fig-align: center
#| fig-width: 12
#| fig-height: 8
#Biometric Gradient Comparison: 5 biomass estimation methods
library(dplyr)
library(terra)
library(tidyverse)

SRGdat <-  read.csv("../Data/GitData/US-SRG_BiometGrad_07062025.csv")%>%
  mutate(Site = "US-SRG")%>%
  group_by(ID)%>%
  summarize(BasalDi = mean(BasalDiameter, na.rm = T),
            CanopyDi = mean(CanopyDiameter, na.rm = T))%>%
  mutate(Basal_bio = exp((-2.9255) + 2.4109 * log(BasalDi)))%>% #in kg
  mutate(area = pi*((CanopyDi/2)^2))

model <- nls(Basal_bio ~ a * area^b,
             data = SRGdat,
             start = list(a = 0.1, b = 1))

SRGdat$Canopy_bio <- predict(model, newdata = SRGdat)

vox_est <- readRDS("../Data/biomet_vox_biomass.RDS")%>%
  rename(Vox_bio = Biomass_kg)%>%
  select(ID, Vox_bio)

biomet_dat <- merge(SRGdat, vox_est, by = "ID")


#-----canopy detection
corrected_coords <- vect("../QGIS/SRGCorrectedTreePoints.shp")
manu_polys <- vect("../Data/GitData/canopypolys.shp")
auto_polys <- vect("../Data/testJiamingcrowns2.shp")
survey_outline <- vect("../QGIS/100msurveybuffer.shp")

manu_polys <- crop(manu_polys, survey_outline)
auto_polys <- crop(auto_polys, survey_outline)

corrected_coords <- project(corrected_coords, "EPSG:32612")

if (!("polyID" %in% names(manu_polys)) || all(is.na(manu_polys$polyID))) {
  manu_polys$polyID <- 1:nrow(manu_polys)
}

if (!("polyID" %in% names(auto_polys)) || all(is.na(auto_polys$polyID))) {
  auto_polys$polyID <- 1:nrow(auto_polys)
}

manual_mapping <- data.frame(
  TreeID = 1:10,
  polyID = c(243, 248, 339, 335, 141, 142, 306, 26, 32, 3)
)

auto_mapping <- data.frame(
  TreeID = c(1, 2, 7, 5, 4, 10, 8),
  polyID = c(125, 221, 330, 334, 356, 243, 246)
)

match_points_to_polygons <- function(points, polygons, model, method_name, mapping = NULL) {
  matched_polys <- list()
  
  for (i in seq_len(nrow(points))) {
    matches <- which(relate(polygons, points[i], "intersects"))
    if (length(matches) > 0) {
      matched_polys[[i]] <- polygons[matches[1], ]
    }
  }
  
  if (length(matched_polys) == 0) return(data.frame())
  
  matched_vec <- do.call(rbind, matched_polys)
  matched_vec$area <- expanse(matched_vec, unit = "m")
  
  if (!is.null(mapping)) {
    df <- as.data.frame(matched_vec)
    df <- df %>%
      left_join(mapping, by = "polyID") %>%
      rename(ID = TreeID)
    matched_vec$ID <- df$ID
  }
  
  df <- as.data.frame(matched_vec)
  df$predicted_biomass <- predict(model, newdata = df)
  df$method <- method_name
  return(df)
}

manual_df <- match_points_to_polygons(
  points = corrected_coords,
  polygons = manu_polys,
  model = model,
  method_name = "Manual",
  mapping = manual_mapping
)

man_df <- manual_df%>%
  rename(manu_bio = predicted_biomass)%>%
  select(ID, manu_bio)

auto_df <- match_points_to_polygons(
  points = corrected_coords,
  polygons = auto_polys,
  model = model,
  method_name = "Automatic",
  mapping = auto_mapping
)


auto_mapping <- data.frame(
  BiometID = c(1, 2, 7, 5, 4, 10, 8),
  treeID = c(125, 221, 330, 334, 356, 243, 246)
)
auto_df <- merge(auto_df, auto_mapping, by = "treeID")
auto_df <- auto_df%>%
  rename(auto_bio = predicted_biomass)%>%
  select(BiometID, auto_bio)%>%
  rename(ID = BiometID)

candetection <- left_join(man_df, auto_df, by = "ID")


#---------complete dataframe---------

biomet_comp <- merge(biomet_dat, candetection, by = "ID")

#---------plot------------------------------------------------------------------
biomet_long <- biomet_comp %>%
  pivot_longer(
    cols = ends_with("_bio"),
    names_to = "method",
    values_to = "biomass"
  ) %>%
  mutate(method = recode(method,
                         Basal_bio = "Basal Diameter",
                         Canopy_bio = "Canopy Area",
                         manu_bio = "Manual Crown",
                         auto_bio = "Automated Crown",
                         Vox_bio = "Voxelization"),
         method = factor(method, levels = c("Basal Diameter", "Canopy Area", "Manual Crown", "Automated Crown", "Voxelization")))

ggplot(biomet_long, aes(x = factor(ID), y = biomass, fill = method)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  scale_fill_viridis_d(option = "D", end = 0.85, name = "Method:") +
  labs(x = "Tree ID", y = "Biomass (kg)", title = "") +
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.major.x = element_blank(),
    legend.position = "bottom",
    axis.text.x = element_text(size = 14),
          axis.text.y = element_text(size = 14),
          axis.title.x = element_text(size = 22),
          axis.title.y = element_text(size = 22),
        legend.text = element_text(size = 18),
        legend.title = element_text(size = 18)
  )
```

## Biomass Products

Direct comparison between the biomass estimates from the methods explored above and existing biomass products is challenging due to the differences in temporal coverage and original spatial resolution. We compare them regardless and observe substantial variability across both fine and large scale approaches.

```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 8
library(dplyr)
library(ggplot2)
library(terra)

# Read and prepare external product data
biomassprods <- read.csv("../Data/AnnualBiomassProducts.csv") %>%
  select(-ffp_radius)

summary_bio <- biomassprods %>%
  filter(SITE_ID == "US-SRG") %>%
  group_by(product) %>%
  summarise(
    max_bio = max(agb_Mg_ha, na.rm = TRUE),
    mean_bio = mean(agb_Mg_ha, na.rm = TRUE),
    recent_year = max(year, na.rm = TRUE),
    recent_bio = agb_Mg_ha[year == recent_year][1],
    .groups = "drop"
  ) %>%
  filter(!is.na(recent_bio)) %>%
  mutate(
    is_zero = recent_bio == 0,
    plot_biomass = ifelse(is_zero, 0.1, recent_bio),
    source = "Product"
  )

# Survey area from shapefile
survey_outline <- vect("../QGIS/100msurveybuffer.shp")
area_m2 <- expanse(survey_outline, unit = "m")
area_ha <- area_m2 / 10000
total_area_ha <- sum(area_ha)

# SRG estimates
srg_bio <- data.frame(
  product = c("basal area", "canopy area", "manual crown", "automated crown", "voxelization"),
  agb_Mg = c(12.66, 11.7, 18.0, 3.8, 46.9),
  recent_year = 2025
) %>%
  mutate(
    recent_bio = agb_Mg / total_area_ha,  # Convert to Mg/ha
    is_zero = recent_bio == 0,
    plot_biomass = ifelse(is_zero, 0.1, recent_bio),
    source = "Report Estimate",
    recent_year = as.character(recent_year)
  )

# Combine
combined_bio <- bind_rows(
  summary_bio %>% select(product, recent_bio, recent_year, plot_biomass, source),
  srg_bio %>% select(product, recent_bio, recent_year, plot_biomass, source)
) %>%
  mutate(product_year = paste0(product, " (", recent_year, ")"))

# Plot
ggplot(combined_bio, aes(x = reorder(product_year, -plot_biomass), y = plot_biomass, fill = source)) +
  geom_col(alpha = 0.9, position = position_dodge(width = 0.7), width = 0.6) +
  scale_fill_manual(values = c("Product" = "skyblue", "Report Estimate" = "forestgreen")) +  # teal & pink
  labs(
    title = "",
    x = "Product (Most Recent Year)",
    y = "AGB (Mg/ha)",
    fill = ""
  ) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "bottom",
    axis.text.x = element_text(size = 18),
          axis.text.y = element_text(size = 18),
          axis.title.x = element_text(size = 22),
          axis.title.y = element_text(size = 22),
        legend.text = element_text(size = 20),
  )+
  coord_flip()
```
